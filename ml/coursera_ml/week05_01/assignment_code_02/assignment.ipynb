{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "data_frame = pandas.read_csv(filepath_or_buffer='gbm-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gena added\n",
    "# type(data_frame)\n",
    "# help(pandas.core.frame.DataFrame.values)\n",
    "# data_frame.info()\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gene: I do not know what it is\n",
    "data = data_frame.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data_frame[\"Activity\"].values\n",
    "X = data_frame.drop(\"Activity\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate : float, optional (default=0.1) - вот не понятно что это \n",
    " |      learning rate shrinks the contribution of each tree by `learning_rate`.\n",
    " |      There is a trade-off between learning_rate and n_estimators.\n",
    " |  \n",
    "n_estimators : int (default=100)\n",
    " |      The number of boosting stages to perform. Gradient boosting\n",
    " |      is fairly robust to over-fitting so a large number usually\n",
    " |      results in better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190           17.90s\n",
      "         2           0.9192           17.56s\n",
      "         3           0.8272           16.80s\n",
      "         4           0.7834           17.50s\n",
      "         5           0.7109           17.06s\n",
      "         6           0.6368           18.03s\n",
      "         7           0.5797           18.18s\n",
      "         8           0.5610           17.85s\n",
      "         9           0.5185           17.54s\n",
      "        10           0.4984           17.40s\n",
      "        20           0.1999           17.24s\n",
      "        30           0.1313           19.14s\n",
      "        40           0.0790           17.18s\n",
      "        50           0.0511           15.58s\n",
      "        60           0.0352           14.28s\n",
      "        70           0.0245           13.17s\n",
      "        80           0.0162           12.20s\n",
      "        90           0.0114           11.28s\n",
      "       100           0.0077           10.45s\n",
      "       200           0.0004            2.97s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255           16.77s\n",
      "         2           1.0035           16.90s\n",
      "         3           0.9386           16.54s\n",
      "         4           0.8844           17.13s\n",
      "         5           0.8381           16.73s\n",
      "         6           0.7995           16.58s\n",
      "         7           0.7559           16.64s\n",
      "         8           0.7205           16.99s\n",
      "         9           0.6958           16.68s\n",
      "        10           0.6725           16.45s\n",
      "        20           0.4672           15.11s\n",
      "        30           0.3179           14.32s\n",
      "        40           0.2274           15.79s\n",
      "        50           0.1774           14.66s\n",
      "        60           0.1394           13.63s\n",
      "        70           0.1050           12.70s\n",
      "        80           0.0805           11.85s\n",
      "        90           0.0650           10.99s\n",
      "       100           0.0511           10.23s\n",
      "       200           0.0058            3.21s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2095           18.19s\n",
      "         2           1.1006           17.06s\n",
      "         3           1.0240           16.99s\n",
      "         4           0.9729           17.58s\n",
      "         5           0.9387           16.87s\n",
      "         6           0.8948           16.59s\n",
      "         7           0.8621           16.77s\n",
      "         8           0.8360           16.48s\n",
      "         9           0.8171           16.18s\n",
      "        10           0.7883           16.27s\n",
      "        20           0.6164           14.94s\n",
      "        30           0.4933           13.97s\n",
      "        40           0.4248           13.22s\n",
      "        50           0.3345           12.66s\n",
      "        60           0.2760           13.74s\n",
      "        70           0.2263           13.01s\n",
      "        80           0.1971           13.41s\n",
      "        90           0.1693           12.38s\n",
      "       100           0.1388           11.41s\n",
      "       200           0.0294            3.42s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613           16.44s\n",
      "         2           1.1715           16.30s\n",
      "         3           1.1009           16.34s\n",
      "         4           1.0529           17.21s\n",
      "         5           1.0130           17.18s\n",
      "         6           0.9740           17.04s\n",
      "         7           0.9475           16.67s\n",
      "         8           0.9197           17.00s\n",
      "         9           0.8979           16.60s\n",
      "        10           0.8730           16.44s\n",
      "        20           0.7207           15.10s\n",
      "        30           0.6055           14.24s\n",
      "        40           0.5244           13.51s\n",
      "        50           0.4501           12.80s\n",
      "        60           0.3908           12.16s\n",
      "        70           0.3372           11.49s\n",
      "        80           0.3009           10.82s\n",
      "        90           0.2603           10.19s\n",
      "       100           0.2327            9.53s\n",
      "       200           0.0835            3.12s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3199           16.10s\n",
      "         2           1.2645           16.08s\n",
      "         3           1.2170           16.35s\n",
      "         4           1.1775           17.18s\n",
      "         5           1.1404           16.98s\n",
      "         6           1.1106           16.81s\n",
      "         7           1.0844           16.71s\n",
      "         8           1.0617           16.85s\n",
      "         9           1.0411           16.68s\n",
      "        10           1.0223           16.49s\n",
      "        20           0.8864           15.39s\n",
      "        30           0.7844           14.50s\n",
      "        40           0.7176           13.63s\n",
      "        50           0.6590           12.87s\n",
      "        60           0.6120           12.17s\n",
      "        70           0.5599           11.50s\n",
      "        80           0.5242           10.80s\n",
      "        90           0.4829           10.14s\n",
      "       100           0.4473            9.51s\n",
      "       200           0.2379            3.36s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "n_estimators = 250\n",
    "# n_estimators = 8\n",
    "\n",
    "\n",
    "def get_result_for_learning_rate(learning_rate):\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_estimators, verbose=True, random_state=241, learning_rate=learning_rate)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    log_loss_train = []\n",
    "    # Gene: что такое staged_decision_function   \n",
    "    for y_pred in clf.staged_decision_function(X_train):\n",
    "        # Gene: что такое  log_los    \n",
    "        log_loss_train.append(log_loss(y_train, 1.0/(1.0 + np.exp(-y_pred))))\n",
    "        \n",
    "    log_loss_test = []\n",
    "    for y_pred in clf.staged_decision_function(X_test):\n",
    "        log_loss_test.append(log_loss(y_test, 1.0/(1.0 + np.exp(-y_pred))))\n",
    "    \n",
    "    return log_loss_train, log_loss_test\n",
    "    \n",
    "scores = []\n",
    "for learning_rate in [1, 0.5, 0.3, 0.2, 0.1]:\n",
    "    log_loss_train, log_loss_test = get_result_for_learning_rate(learning_rate)\n",
    "    scores.append((learning_rate, log_loss_train, log_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for learning_rate_data in scores:\n",
    "#     fig = plt.figure()\n",
    "#     fig.canvas.set_window_title(learning_rate_data[0]) \n",
    "#     plt.plot(learning_rate_data[1], 'g', linewidth=2)\n",
    "#     plt.plot(learning_rate_data[2], 'r', linewidth=2)\n",
    "#     plt.legend([\"train\", \"test\"])\n",
    "#     plt.show()\n",
    "\n",
    "[1, 0.5, 0.3, 0.2, 0.1]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(scores[0][1], 'b', linewidth=1)\n",
    "plt.plot(scores[0][2], 'b--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[1][1], 'g', linewidth=1)\n",
    "plt.plot(scores[1][2], 'g--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[2][1], 'r', linewidth=1)\n",
    "plt.plot(scores[2][2], 'r--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[3][1], 'c', linewidth=1)\n",
    "plt.plot(scores[3][2], 'c--', linewidth=1)\n",
    "\n",
    "plt.plot(scores[4][1], 'm', linewidth=1)\n",
    "plt.plot(scores[4][2], 'm--', linewidth=1)\n",
    "\n",
    "plt.legend([\"1-train\", \"1-test\", \n",
    "            \"0.5-train\", \"0.5-test\", \n",
    "            \"0.3-train\", \"0.3-test\", \n",
    "            \"0.2-train\", \"0.2-test\", \n",
    "            \"0.1-train\", \"0.1-test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "0.530918156803\n"
     ]
    }
   ],
   "source": [
    "print(scores[3][2].index(min(scores[3][2])))\n",
    "print(min(scores[3][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=37, n_jobs=1,\n",
       "            oob_score=False, random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_forest = RandomForestClassifier(n_estimators=37, random_state=241)\n",
    "clf_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54091190993698968"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predictions[:, 1]\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
